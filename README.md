# CitiBike-2017
CitiBike 2017 Data Report, README
Matthew Giancristofaro

Purpose

In this file, you will find data reports and visualizations on the 2017 monthly data provided by CitiBike. The purpose of this report is to find information and provide visualizations for the following:

1) Top 5 stations with the most starts
2) Trip duration by user type
3) Most popular trips based on start station and stop station
4) Rider performance by Gender and Age based on average trip distance (station to station), median speed (trip duration / distance traveled)
5) Busiest Bike in 2017, number of times it was used, number of minutes in use

Lastly, this file contains a predictive model to estimate the trip duration if a user were to input the start and end station. 

Process

The following reports were created first by importing the monthly data reports generated by CitiBike. Python code on a Jupyter was then used to organize, clean, and analyze the data and to create visualizations. I used the pandas, numpy, matplotlib.pyplot, seaborn, datetime, sklearn, and statsmodels packages to run all the different analyses in this file. 

For different reports and visualizations, the data was cleaned based on assumptions. This involved removing anomalies that would impact the accuracy of the data reports, and were justified for the sake of accuracy. Removing these anomalies will be discussed in further detail down below. 

Lastly, the predictive model was created. This involved bringing in an external data set, weather, and running various iterations of a Linear Regression model to improve the accuracy based on calculated R2 values. 

i. Importing the Data

To import the data, I downloaded all 12 monthly reports generated by CitiBike and used pandas to import the different csv’s. Because months January, February and March had different column names, I had to fix those columns before concatenating into one master data frame. After combining the 12 dataframes into one, I saved the csv as “2017 Citibike Data.csv”. 

Part 1: Top 5 Stations with the Most Starts

To create this report, I took the column “start station name’ from the master dataframe and created a new data frame called “start_stations_df”. Using this dataframe, I used the value_counts() function to count the frequency of each start station name and listed the top 5 most frequent. Using these values, I created a new data frame with the station name and frequency, and used this data frame to create a horizontal bar graph displaying the number of trips at that start station. 

The top five stations are as follows:
1.	Pershing Square North (Used 162,716 times)
2.	E 17th & Broadway (Used 112,218 times)
3.	Broadway & E 22nd St (Used 108,590 times)
4.	West 21st & 6th Ave (Used 107,133 times)
5.	West St & Chambers St (Used 105,610 times)


Part 2: Trip Duration by User Type

In this part of the code, I determine information about the trip duration that is filtered by the two user types, Customer and Subscribers. Customers are users who have purchases a day or three day pass, and subscribers are users who have purchased the annual pass. 

To create my report I went through the following steps:

1) Create a new dataframe that indexes the columns 'tripduration' and 'usertype' from the dataframe

2) Clean the data: 
    a.	Remove all rows where tripduration is less than 90 seconds. This assumes that the user mistakenly took a bike out and immediately docked it back in the station.
    b.	Remove all rows where trip duration is greater than 2.5 hours. CitiBikes website says the max trip duration for customers before getting charged is 30 minutes and for subscribers 45 minutes. Therefore, it is safe to assume that bikes that were docked after 2.5 hours may have been mis-docked. Removing this data is less than 8% of the total data and would therefore not impact overall data insights but would remove potential anomalies.  

3) Convert the trip duration column into minutes. This allows a graph to be created that will not have an extremely massive y-scale because of large amounts of seconds. This makes the graph more manageable and readable. 

4) Create a box plot that is grouped by user type. This boxplot reveals several pieces of necessary information for the customer to view, such as median, min and max trip durations.

The Trip Duration by user type demonstrates that Customers travel longer than subscribers. The median trip duration for a customer is 21 minutes while a subscriber is just under 10 minutes:


Part 3: Most Popular Trips in 2017

In this part of the code, I determined the most popular trips taken based on start and end stations. To do so, I did the following: 

1) Create a new data frame that only contains the columns “start station name” and “end station name” from the master data frame. In this data frame, clean the data to remove any rows of data with trip duration under 1.5 minutes and over 2.5 hours. As mentioned before, because we are creating a report of specific trips, anomalies may not accurately represent a real ‘trip’. 

2) Group the data frame first by ‘start station name’ and then ‘end station name’ and count its frequency. Place that frequency value in a new column called "number of trips".

4) Create a new column that concatenates the start and end station name to read "Station A to Station B".

3) Sort the new data frame by number of trips, and call the top ten.

4) Plot this data frame on a bar graph, revealing the number of trips taken per each trip. 

The most popular trips are as follows: 
1.	Central Park S & 6 Ave to Central Park S & 6th Ave (made 6,788 times)
2.	Central Park S & 6th Ave to 5th Ave & East 88th St. (made 6,304 times)
3.	East 7th St & Ave A to Cooper Square & East 7 St (made 5,972 times)
4.	12th Ave & West 40th St to West St & Chambers St (made 5,396 times)
5.	Grand Army Plaza & Central Park to Grand Army Plaza & Central Park (made 5,234 times)

Part 4: Determining Rider Performance by Gender and Age for Average Distance and Median Speed

This part of the code took many steps, including cleaning during a few phases. 

Part 1: Calculate the distance between a given start and end station

1) Create a new data frame from the master dataframe with only the coordinates for each station

2) Import the math package and use the Haversine Formula with a for loop to append an empty list that contains every calculated distance for each trip made. This output is distance in kilometers.

3) Finally, use the newly created list full of generated distances and create a new column “Distance in km” in the master data frame. This new column will be useful in future steps. 

Part 2: Calculate average distance and median speed for groups grouped by gender and age

1) Create a data frame from the master data frame that contains the columns ‘gender’, ‘birth year’, ‘tripduration’ and ‘distance travelled’ 

2) Clean the data so all rows containing NAN values are dropped (this occurs in both gender and birth year columns), and remove anyone 70 years and older. The reason in doing so is because a) several individuals have an age of over 100, which is safe to remove, and b) anyone over 70 is 2 standard deviations above the mean age. 

3) Create a new column named "Age" that is 2017 minus each rider's birth year. 

4) Remove all rows that distance is 0 because that will skew all the data. This report is measuring rider performance by trip distance and trip distance of 0 does not account for the fact a ride may have taken a loop. 

5) Determine the mean distance of each distinct group by grouping by gender and age and finding the mean speed using the .mean() function on the column “Distance in km”.

6) Create a new column, ‘Speed in m/s’, that takes the distance travelled, converted to meters, and divided by tripduration.

7) Group the data frame by Gender and then Age and find the median speed of each distinct group using the .median() function on the “speed in m/s” column. 

8) Lastly, to plot on a scatter plot various customizations are needed. First, I created a new list that attaches a distinct color for each gender, unknown = yellow, male=blue, female = red. This was created using a for loop.

9) I then plotted this scatterplot using .scatter() where the y axis is Median Speed, X Axis is average trip distance, the color of the dots represent gender, and the size of the dot represent age.

Part 5: Busiest Bike

In this part of the code, I determine the busiest bike used in 2017 and calculate the number of trips it made and the number of minutes it was in use.

1) Create a data frame that groups the master data frame by bike id and then creates a new column that included each frequency value

2) Sort the data frame by number of trips made, and take the top 5

3) To calculate minutes in use, I created a for loop that takes the master dataframe, then filters it by each unique bikeid. When the master data only shows rows for that unique bike id, it calculated the sum of the column ‘tripduration’, and divides by 60 to calculate minutes. This value is added to an empty list, busybikelist, which is then added as a new column in the data frame after the for loop ends. 

4) Last part is to plot this information. I created a twin bargraph with two different y axes. The first y axis measures number of trips made and the second y axis reveals minutes in use.

The busiest bike was bike no. 25738. It was used 2,514 times for a total of 40,971 minutes in 2017. 



Part 6: Predictive Model
Prepping the Data for the Predictive Model

In this part of the code, I prepped my master data frame and other additional information to be used in a predictive linear regression model. 

1) First, I created a column in the master data frame that is only the day of year the bike was used by splitting it from the time. The purpose of this was to prep my information for the merging of weather data AND to include start day as a predictor variable

2) Take the gender column and turn them into strings, creating categorical variables that will be prepared to be dummified

3) Fix all NaN's in the 'age' column by assigning them as 0 instead of NaN

4) Import weather data from Wunderground

5) Use a left join to merge the data from Wunderground with the master dataframe. To join them, I used the day of year column.

6) Clean the data by removing all NaN's from the 'Event' column from the weather data, and drop all rows where the tripduration is greater than 2.5 hours. Again, the model cannot handle NaN values and anomalies will skew the prediction accuracy of the model.

7) Create a new column titled "day of week" that takes each day of the year and turns it into a number 0-6, 0=Monday…6=Sunday, using the DateTime package

8) Lastly, save this new data frame as a csv to be later used in the predictive modeling portion

Creating the Linear Regression Model
In this code, I use the prepped dataframe from prior steps that merged the weather data with the citibike data. I run a series of tests on sample data to determine the right variables to use in my Linear Regression model. To start, I imported all necessary packages, including the model packages from SciKitLearn

Step 1) I cleaned the data to improve my accuracy results. Any data that would be considered outliers would skew the accuracy of my results.

Step 2) To prepare to dummy my categorical variables, i created new columns in the dataframe for ‘day of week’ and ‘month of year’

Step 3) I took a random sample (6.7% or ~1,000,000 rows) of the master data frame to make the data more manageable when running tests

Step 4) Using this random sample, I dummified all my categorical data such as gender, usertype, weather event, day of week and month of year

Step 5) I concatenated these dummies with the original random sample

Step 6) I created a coefficient matrix and indexed only the trip duration column to determine which variables have the strongest impact on trip duration. I will be initially using these variables in the master model

Step 7) Normalize the continuous variables that will impact trip duration because the scales of those variable are all different and normalizing places them on the right scale. 

Step 8) User the original master data frame to create dummies of the same ones used in the random sample and then concatenate this data frame with the original. This master data frame will be used for the model. 

Step 9) Take a random sample (8.5%) of this new concatenated master data frame to have one more manageable to work with 

Step 10) Create two data frames, one with only trip duration (the target variable) and one with all the remaining predictor variables

Step 11) Create the test and training sets, with 20% for testing and 80% for training.

Step 12) Run the model and calculate the R^2 to reveal model accuracy. In this case, the R2 value of my model was 0.699 using the variables “Distance in km,” “Age,” “Temperature high (F),” “usertype,” and “gender”

DISCLAIMER: In this model, the start and end station names were not included as variables. While the prompt asked for these inputs, my computer could not successfully dummify these variables without crashing. Therefore, my model uses “Distance in km” in replacement, as these values will accommodate for every combination of start and end station.

